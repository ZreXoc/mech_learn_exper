(exp) u2023112918@n1:~/mech_exper$ tail -f nohup.out 
/home/u2023112918/.conda/envs/exp/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
Some weights of BertForTokenClassification were not initialized from the model checkpoint at /home/u2023112918/models/models--bert-base-chinese/ and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{0: 'B-BANK', 1: 'I-BANK', 2: 'B-PRODUCT', 3: 'I-PRODUCT', 4: 'B-COMMENTS_N', 5: 'I-COMMENTS_N', 6: 'B-COMMENTS_ADJ', 7: 'I-COMMENTS_ADJ', 8: 'O', 9: '[UNK]', 10: '[PAD]'}
100%|██████████| 25/25 [00:50<00:00,  2.02s/it]
Epochs: 1 | 
                Loss:  0.43946915 | 
                Accuracy:  0.45258530 |
               
100%|██████████| 25/25 [00:49<00:00,  1.98s/it]
Epochs: 2 | 
                Loss:  0.09669251 | 
                Accuracy:  0.82460349 |
               
100%|██████████| 25/25 [00:49<00:00,  1.98s/it]
Epochs: 3 | 
                Loss:  0.06878769 | 
                Accuracy:  0.86092942 |
               
100%|██████████| 25/25 [00:49<00:00,  1.97s/it]
Epochs: 4 | 
                Loss:  0.05417553 | 
                Accuracy:  0.88207691 |
               
100%|██████████| 25/25 [00:49<00:00,  1.98s/it]
Epochs: 5 | 
                Loss:  0.04717406 | 
                Accuracy:  0.89496536 |
               
100%|██████████| 25/25 [00:49<00:00,  1.98s/it]
Epochs: 6 | 
                Loss:  0.04266753 | 
                Accuracy:  0.90365578 |
               
100%|██████████| 25/25 [00:49<00:00,  1.98s/it]
Epochs: 7 | 
                Loss:  0.03900751 | 
                Accuracy:  0.91187253 |
               
100%|██████████| 25/25 [00:49<00:00,  1.97s/it]
Epochs: 8 | 
                Loss:  0.03532228 | 
                Accuracy:  0.91983987 |
               
100%|██████████| 25/25 [00:49<00:00,  1.98s/it]
Epochs: 9 | 
                Loss:  0.03185332 | 
                Accuracy:  0.92874894 |
               
100%|██████████| 25/25 [00:49<00:00,  1.97s/it]
Epochs: 10 | 
                Loss:  0.02884529 | 
                Accuracy:  0.93404715 |
               
100%|██████████| 25/25 [00:49<00:00,  1.98s/it]
Epochs: 11 | 
                Loss:  0.02651921 | 
                Accuracy:  0.93802681 |
               
100%|██████████| 25/25 [00:49<00:00,  1.98s/it]
Epochs: 12 | 
                Loss:  0.02459820 | 
                Accuracy:  0.94227438 |
               
100%|██████████| 25/25 [00:49<00:00,  1.97s/it]
Epochs: 13 | 
                Loss:  0.02292099 | 
                Accuracy:  0.94493305 |
               
100%|██████████| 25/25 [00:49<00:00,  1.97s/it]
Epochs: 14 | 
                Loss:  0.02126005 | 
                Accuracy:  0.94870165 |
               
100%|██████████| 25/25 [00:49<00:00,  1.98s/it]
Epochs: 15 | 
                Loss:  0.02008519 | 
                Accuracy:  0.95104168 |
               
100%|██████████| 25/25 [00:49<00:00,  1.98s/it]
Epochs: 16 | 
                Loss:  0.01890427 | 
                Accuracy:  0.95378147 |
               
100%|██████████| 25/25 [00:49<00:00,  1.98s/it]
Epochs: 17 | 
                Loss:  0.01758074 | 
                Accuracy:  0.95697235 |
               
100%|██████████| 25/25 [00:49<00:00,  1.98s/it]
Epochs: 18 | 
                Loss:  0.01657448 | 
                Accuracy:  0.95895461 |
               
100%|██████████| 25/25 [00:49<00:00,  1.98s/it]
Epochs: 19 | 
                Loss:  0.01572968 | 
                Accuracy:  0.96105512 |
               
100%|██████████| 25/25 [00:49<00:00,  1.98s/it]
Epochs: 20 | 
                Loss:  0.01458860 | 
                Accuracy:  0.96352271 |
               
^C[1]+  Done                    nohup python train.py
